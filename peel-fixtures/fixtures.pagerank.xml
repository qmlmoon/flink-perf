<?xml version="1.0" encoding="UTF-8"?>

<beans xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.springframework.org/schema/beans"
       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd">

    <!--************************************************************************
    * Custom Systems
    *************************************************************************-->

    <!-- Use lifespan "PROVIDED" if you want to start the systems manually   -->
    <!-- Use lifespan "SUITE" if you want PEEL to deploy to start them       -->

    <!-- Hadoop Distributed File System (overridden 'hdfs-1' bean) -->
    <bean id="hdfs-1" class="eu.stratosphere.peel.extensions.hadoop.beans.system.HDFS1" parent="system">
        <constructor-arg name="version" value="1.2.1"/>
        <constructor-arg name="lifespan" value="SUITE"/>
        <constructor-arg name="dependencies">
            <set value-type="eu.stratosphere.peel.core.beans.system.System">
            </set>
        </constructor-arg>
    </bean>

    <!-- Hadoop Distributed File System (overridden 'hdfs-2' bean) -->
   <!--  <bean id="hdfs-2" class="eu.stratosphere.peel.extensions.hadoop.beans.system.HDFS2" parent="system">
        <constructor-arg name="version" value="2.4.1"/>
        <constructor-arg name="lifespan" value="SUITE"/>
        <constructor-arg name="dependencies">
            <set value-type="eu.stratosphere.peel.core.beans.system.System">
            </set>
        </constructor-arg>
    </bean> -->

    <!-- Flink (overridden 'flink' bean that depends on HDFS1) -->
    <bean id="flink" class="eu.stratosphere.peel.extensions.flink.beans.system.Flink" parent="system" abstract="true">
        <constructor-arg name="lifespan" value="SUITE"/>
        <constructor-arg name="dependencies">
            <set value-type="eu.stratosphere.peel.core.beans.system.System">
                <ref bean="hdfs-1"/>
            </set>
        </constructor-arg>
    </bean>

    <!-- Flink (version 0.7.0) -->
    <bean id="flink-0.7.0" parent="flink">
        <constructor-arg name="version" value="0.7.0"/>
    </bean>

    <!-- Spark (overridden spark bean that depends on hdfs -->
    <bean id="spark" class="eu.stratosphere.peel.extensions.spark.beans.system.Spark" parent="system" abstract="true">
        <constructor-arg name="lifespan" value="SUITE"/>
        <constructor-arg name="dependencies">
            <set value-type="eu.stratosphere.peel.core.beans.system.System.System">
                <ref bean="hdfs-1"/>
            </set>
        </constructor-arg>
    </bean>

    <!-- Spark (version 1.1) -->
    <bean id="spark-1.1" parent="spark">
        <constructor-arg name="version" value="1.1.0"/>
    </bean>

    <!--************************************************************************
    * Data Sets
    *************************************************************************-->

    <!-- Page Rank input -->
    <bean id="dataset.flickr" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/graph/flickr-links/out.flickr-links.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/flickr"/>
    </bean>
    <bean id="dataset.dbpedia" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/graph/dbpedia-link/out.dbpedia-link.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/dbpedia"/>
    </bean>
    <bean id="dataset.twitter" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/graph/twitter/out.twitter.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/twitter"/>
    </bean>
   

    <!-- pagerank output -->
    <bean id="experiment.output.hdfs.pagerank" parent="experiment.output.hdfs-1">
        <constructor-arg name="path" value="${system.hadoop-1.path.output}/pagerank"/>
    </bean>

    <!--************************************************************************
    * Experiments
    *************************************************************************-->

    <!-- Experiment beans -->
    <bean id="experiment.flink" class="eu.stratosphere.peel.extensions.flink.beans.experiment.FlinkExperiment" abstract="true">
        <constructor-arg name="runner" ref="flink-0.7.0"/>
        <constructor-arg name="runs" value="5"/>
    </bean>

    <bean id="experiment.spark" class="eu.stratosphere.peel.extensions.spark.beans.experiment.SparkExperiment" abstract="true">
        <constructor-arg name="runner" ref="spark-1.1"/>
        <constructor-arg name="runs" value="5"/>
    </bean>


    <!-- pagerank experiments -->
    <bean id="experiment.flink.pagerank.flickr" parent="experiment.flink" abstract="true">
        <constructor-arg name="command">
            <value>-c com.github.projectflink.testPlan.PageRank ${app.path.jobs}/flink-jobs-0.1-SNAPSHOT-FlinkBench.jar ${system.hadoop-1.path.input}/flickr ${system.hadoop-1.path.output}/pagerank 1715255 10</value>
        </constructor-arg>
        <constructor-arg name="input">
           <ref bean="dataset.flickr" />
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.pagerank"/>
        </constructor-arg>
    </bean>

    <bean id="experiment.flink.pagerank.dbpedia" parent="experiment.flink" abstract="true">
        <constructor-arg name="command">
            <value>-c com.github.projectflink.testPlan.PageRank ${app.path.jobs}/flink-jobs-0.1-SNAPSHOT-FlinkBench.jar ${system.hadoop-1.path.input}/dbpedia ${system.hadoop-1.path.output}/pagerank 18268992 10</value>
        </constructor-arg>
        <constructor-arg name="input">
           <ref bean="dataset.dbpedia" />
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.pagerank"/>
        </constructor-arg>
    </bean>

    <bean id="experiment.flink.pagerank.twitter" parent="experiment.flink" abstract="true">
        <constructor-arg name="command">
            <value>-c com.github.projectflink.testPlan.PageRank ${app.path.jobs}/flink-jobs-0.1-SNAPSHOT-FlinkBench.jar ${system.hadoop-1.path.input}/twitter ${system.hadoop-1.path.output}/pagerank 41652230 10</value>
        </constructor-arg>
        <constructor-arg name="input">
           <ref bean="dataset.twitter" />
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.pagerank"/>
        </constructor-arg>
    </bean>


    <bean id="experiment.spark.pagerank.flickr" parent="experiment.spark" abstract="true">
        <constructor-arg name="command">
            <value>--class com.github.projectflink.spark.PageRank ${app.path.jobs}/spark-jobs-0.1-SNAPSHOT-SparkBench.jar ${system.spark.config.defaults.spark.master} ${system.hadoop-1.path.input}/flickr ${system.hadoop-1.path.output}/pagerank 1715255 10</value>
        </constructor-arg>
         <constructor-arg name="input">
           <ref bean="dataset.flickr" />
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.pagerank"/>
        </constructor-arg>
    </bean>

   <bean id="experiment.spark.pagerank.dbpedia" parent="experiment.spark" abstract="true">
        <constructor-arg name="command">
            <value>--class com.github.projectflink.spark.PageRank ${app.path.jobs}/spark-jobs-0.1-SNAPSHOT-SparkBench.jar ${system.spark.config.defaults.spark.master} ${system.hadoop-1.path.input}/dbpedia ${system.hadoop-1.path.output}/pagerank 18268992 10</value>
        </constructor-arg>
         <constructor-arg name="input">
           <ref bean="dataset.dbpedia" />
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.pagerank"/>
        </constructor-arg>
    </bean>

    <bean id="experiment.spark.pagerank.twitter" parent="experiment.spark" abstract="true">
        <constructor-arg name="command">
            <value>--class com.github.projectflink.spark.PageRank ${app.path.jobs}/spark-jobs-0.1-SNAPSHOT-SparkBench.jar ${system.spark.config.defaults.spark.master} ${system.hadoop-1.path.input}/twitter ${system.hadoop-1.path.output}/pagerank 41652230 10</value>
        </constructor-arg>
         <constructor-arg name="input">
           <ref bean="dataset.twitter" />
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.pagerank"/>
        </constructor-arg>
    </bean>

    <!--************************************************************************
    * Fixtures
    *************************************************************************-->

    <bean id="pagerank.flink.flickr.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.pagerank.flickr">
                    <constructor-arg name="name" value="pagerank.flickr.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="pagerank.flink.flickr.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.pagerank.flickr">
                    <constructor-arg name="name" value="pagerank.flickr.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="pagerank.flink.dbpedia.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.pagerank.dbpedia">
                    <constructor-arg name="name" value="pagerank.dbpedia.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="pagerank.flink.dbpedia.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.pagerank.dbpedia">
                    <constructor-arg name="name" value="pagerank.dbpedia.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="pagerank.flink.twitter.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

     <bean id="pagerank.flink.twitter.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop64.mem5G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 5120
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop64.mem10G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 10240
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop64.mem20G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 20480
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop48.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 48
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop32.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 32
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop16.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 16
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="pagerank.spark.flickr.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.pagerank.flickr">
                    <constructor-arg name="name" value="pagerank.flickr.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="pagerank.spark.flickr.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.pagerank.flickr">
                    <constructor-arg name="name" value="pagerank.flickr.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="pagerank.spark.dbpedia.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.pagerank.dbpedia">
                    <constructor-arg name="name" value="pagerank.dbpedia.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="pagerank.spark.dbpedia.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.pagerank.dbpedia">
                    <constructor-arg name="name" value="pagerank.dbpedia.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>


    <bean id="pagerank.spark.twitter.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="pagerank.spark.twitter.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop64.mem5G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "5120m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "5120m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "5120m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop64.mem10G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "10240m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "10240m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "10240m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop64.mem20G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "20480m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "20480m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "20480m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop48.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 48
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop32.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 32
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.pagerank.twitter">
                    <constructor-arg name="name" value="pagerank.twitter.dop16.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 36000
                            system.default.config.slaves = [ "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 16
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>
 
</beans>
