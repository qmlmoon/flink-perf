<?xml version="1.0" encoding="UTF-8"?>

<beans xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.springframework.org/schema/beans"
       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd">

    <!--************************************************************************
    * Custom Systems
    *************************************************************************-->

    <!-- Use lifespan "PROVIDED" if you want to start the systems manually   -->
    <!-- Use lifespan "SUITE" if you want PEEL to deploy to start them       -->

    <!-- Hadoop Distributed File System (overridden 'hdfs-1' bean) -->
    <bean id="hdfs-1" class="eu.stratosphere.peel.extensions.hadoop.beans.system.HDFS1" parent="system">
        <constructor-arg name="version" value="1.2.1"/>
        <constructor-arg name="lifespan" value="SUITE"/>
        <constructor-arg name="dependencies">
            <set value-type="eu.stratosphere.peel.core.beans.system.System">
            </set>
        </constructor-arg>
    </bean>

    <!-- Hadoop Distributed File System (overridden 'hdfs-2' bean) -->
   <!--  <bean id="hdfs-2" class="eu.stratosphere.peel.extensions.hadoop.beans.system.HDFS2" parent="system">
        <constructor-arg name="version" value="2.4.1"/>
        <constructor-arg name="lifespan" value="SUITE"/>
        <constructor-arg name="dependencies">
            <set value-type="eu.stratosphere.peel.core.beans.system.System">
            </set>
        </constructor-arg>
    </bean> -->

    <!-- Flink (overridden 'flink' bean that depends on HDFS1) -->
    <bean id="flink" class="eu.stratosphere.peel.extensions.flink.beans.system.Flink" parent="system" abstract="true">
        <constructor-arg name="lifespan" value="SUITE"/>
        <constructor-arg name="dependencies">
            <set value-type="eu.stratosphere.peel.core.beans.system.System">
                <ref bean="hdfs-1"/>
            </set>
        </constructor-arg>
    </bean>

    <!-- Flink (version 0.7.0) -->
    <bean id="flink-0.7.0" parent="flink">
        <constructor-arg name="version" value="0.7.0"/>
    </bean>

    <!-- Spark (overridden spark bean that depends on hdfs -->
    <bean id="spark" class="eu.stratosphere.peel.extensions.spark.beans.system.Spark" parent="system" abstract="true">
        <constructor-arg name="lifespan" value="SUITE"/>
        <constructor-arg name="dependencies">
            <set value-type="eu.stratosphere.peel.core.beans.system.System.System">
                <ref bean="hdfs-1"/>
            </set>
        </constructor-arg>
    </bean>

    <!-- Spark (version 1.1) -->
    <bean id="spark-1.1" parent="spark">
        <constructor-arg name="version" value="1.1.0"/>
    </bean>

    <!--************************************************************************
    * Data Sets
    *************************************************************************-->

    <!-- TPCH3 input -->
    <bean id="dataset.tpch3.10G.lineitem" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.10G/lineitem.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.10G/lineitem.tbl"/>
    </bean>
    <bean id="dataset.tpch3.10G.orders" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.10G/orders.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.10G/orders.tbl"/>
    </bean>
    <bean id="dataset.tpch3.10G.customer" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.10G/customer.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.10G/customer.tbl"/>
    </bean>

    <bean id="dataset.tpch3.20G.lineitem" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.20G/lineitem.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.20G/lineitem.tbl"/>
    </bean>
    <bean id="dataset.tpch3.20G.orders" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.20G/orders.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.20G/orders.tbl"/>
    </bean>
    <bean id="dataset.tpch3.20G.customer" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.20G/customer.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.20G/customer.tbl"/>
    </bean>

    <bean id="dataset.tpch3.30G.lineitem" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.30G/lineitem.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.30G/lineitem.tbl"/>
    </bean>
    <bean id="dataset.tpch3.30G.orders" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.30G/orders.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.30G/orders.tbl"/>
    </bean>
    <bean id="dataset.tpch3.30G.customer" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.30G/customer.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.30G/customer.tbl"/>
    </bean>

    <bean id="dataset.tpch3.40G.lineitem" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.40G/lineitem.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.40G/lineitem.tbl"/>
    </bean>
    <bean id="dataset.tpch3.40G.orders" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.40G/orders.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.40G/orders.tbl"/>
    </bean>
    <bean id="dataset.tpch3.40G.customer" parent="dataset.static.hdfs-1">
        <constructor-arg name="src" value="${app.path.datasets}/tpch3/tpch.40G/customer.tbl.gz"/>
        <constructor-arg name="dst" value="${system.hadoop-1.path.input}/tpch3.40G/customer.tbl"/>
    </bean>
   

    <!-- TPCH3 output -->
    <bean id="experiment.output.hdfs.tpch3" parent="experiment.output.hdfs-1">
        <constructor-arg name="path" value="${system.hadoop-1.path.output}/tpch3"/>
    </bean>

    <!--************************************************************************
    * Experiments
    *************************************************************************-->

    <!-- Experiment beans -->
    <bean id="experiment.flink" class="eu.stratosphere.peel.extensions.flink.beans.experiment.FlinkExperiment" abstract="true">
        <constructor-arg name="runner" ref="flink-0.7.0"/>
        <constructor-arg name="runs" value="5"/>
    </bean>

    <bean id="experiment.spark" class="eu.stratosphere.peel.extensions.spark.beans.experiment.SparkExperiment" abstract="true">
        <constructor-arg name="runner" ref="spark-1.1"/>
        <constructor-arg name="runs" value="5"/>
    </bean>


    <!-- TPCH3 experiments -->
    <bean id="experiment.flink.tpch3.10G" parent="experiment.flink" abstract="true">
        <constructor-arg name="command">
            <value>-c com.github.projectflink.testPlan.TPCHQuery3 ${app.path.jobs}/flink-jobs-0.1-SNAPSHOT-FlinkBench.jar ${system.hadoop-1.path.input}/tpch3.10G/lineitem.tbl ${system.hadoop-1.path.input}/tpch3.10G/customer.tbl ${system.hadoop-1.path.input}/tpch3.10G/orders.tbl  ${system.hadoop-1.path.output}/tpch3</value>
        </constructor-arg>
        <constructor-arg name="inputs">
            <set value-type="eu.stratosphere.peel.core.beans.data.DataSet">
                <ref bean="dataset.tpch3.10G.lineitem"/>
                <ref bean="dataset.tpch3.10G.orders" />
                <ref bean="dataset.tpch3.10G.customer" />
            </set>
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.tpch3"/>
        </constructor-arg>
    </bean>

   <bean id="experiment.flink.tpch3.20G" parent="experiment.flink" abstract="true">
        <constructor-arg name="command">
            <value>-c com.github.projectflink.testPlan.TPCHQuery3 ${app.path.jobs}/flink-jobs-0.1-SNAPSHOT-FlinkBench.jar ${system.hadoop-1.path.input}/tpch3.20G/lineitem.tbl ${system.hadoop-1.path.input}/tpch3.20G/customer.tbl ${system.hadoop-1.path.input}/tpch3.20G/orders.tbl  ${system.hadoop-1.path.output}/tpch3</value>
        </constructor-arg>
        <constructor-arg name="inputs">
            <set value-type="eu.stratosphere.peel.core.beans.data.DataSet">
                <ref bean="dataset.tpch3.20G.lineitem"/>
                <ref bean="dataset.tpch3.20G.orders" />
                <ref bean="dataset.tpch3.20G.customer" />
            </set>
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.tpch3"/>
        </constructor-arg>
    </bean>

    <bean id="experiment.flink.tpch3.30G" parent="experiment.flink" abstract="true">
        <constructor-arg name="command">
            <value>-c com.github.projectflink.testPlan.TPCHQuery3 ${app.path.jobs}/flink-jobs-0.1-SNAPSHOT-FlinkBench.jar ${system.hadoop-1.path.input}/tpch3.30G/lineitem.tbl ${system.hadoop-1.path.input}/tpch3.30G/customer.tbl ${system.hadoop-1.path.input}/tpch3.30G/orders.tbl  ${system.hadoop-1.path.output}/tpch3</value>
        </constructor-arg>
        <constructor-arg name="inputs">
            <set value-type="eu.stratosphere.peel.core.beans.data.DataSet">
                <ref bean="dataset.tpch3.30G.lineitem"/>
                <ref bean="dataset.tpch3.30G.orders" />
                <ref bean="dataset.tpch3.30G.customer" />
            </set>
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.tpch3"/>
        </constructor-arg>
    </bean>

    <bean id="experiment.flink.tpch3.40G" parent="experiment.flink" abstract="true">
        <constructor-arg name="command">
            <value>-c com.github.projectflink.testPlan.TPCHQuery3 ${app.path.jobs}/flink-jobs-0.1-SNAPSHOT-FlinkBench.jar ${system.hadoop-1.path.input}/tpch3.40G/lineitem.tbl ${system.hadoop-1.path.input}/tpch3.40G/customer.tbl ${system.hadoop-1.path.input}/tpch3.40G/orders.tbl  ${system.hadoop-1.path.output}/tpch3</value>
        </constructor-arg>
        <constructor-arg name="inputs">
            <set value-type="eu.stratosphere.peel.core.beans.data.DataSet">
                <ref bean="dataset.tpch3.40G.lineitem"/>
                <ref bean="dataset.tpch3.40G.orders" />
                <ref bean="dataset.tpch3.40G.customer" />
            </set>
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.tpch3"/>
        </constructor-arg>
    </bean>

    <bean id="experiment.spark.tpch3.10G" parent="experiment.spark" abstract="true">
        <constructor-arg name="command">
            <value>--class com.github.projectflink.spark.TPCHQuery3 ${app.path.jobs}/spark-jobs-0.1-SNAPSHOT-SparkBench.jar ${system.spark.config.defaults.spark.master} ${system.hadoop-1.path.input}/tpch3.10G/lineitem.tbl ${system.hadoop-1.path.input}/tpch3.10G/customer.tbl ${system.hadoop-1.path.input}/tpch3.10G/orders.tbl  ${system.hadoop-1.path.output}/tpch3</value>
        </constructor-arg>
        <constructor-arg name="inputs">
            <set value-type="eu.stratosphere.peel.core.beans.data.DataSet">
                <ref bean="dataset.tpch3.10G.lineitem"/>
                <ref bean="dataset.tpch3.10G.orders" />
                <ref bean="dataset.tpch3.10G.customer" />
            </set>
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.tpch3"/>
        </constructor-arg>
    </bean>

   <bean id="experiment.spark.tpch3.20G" parent="experiment.spark" abstract="true">
        <constructor-arg name="command">
            <value>--class com.github.projectflink.spark.TPCHQuery3 ${app.path.jobs}/spark-jobs-0.1-SNAPSHOT-SparkBench.jar ${system.spark.config.defaults.spark.master} ${system.hadoop-1.path.input}/tpch3.20G/lineitem.tbl ${system.hadoop-1.path.input}/tpch3.20G/customer.tbl ${system.hadoop-1.path.input}/tpch3.20G/orders.tbl  ${system.hadoop-1.path.output}/tpch3</value>
        </constructor-arg>
        <constructor-arg name="inputs">
            <set value-type="eu.stratosphere.peel.core.beans.data.DataSet">
                <ref bean="dataset.tpch3.20G.lineitem"/>
                <ref bean="dataset.tpch3.20G.orders" />
                <ref bean="dataset.tpch3.20G.customer" />
            </set>
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.tpch3"/>
        </constructor-arg>
    </bean>

     <bean id="experiment.spark.tpch3.30G" parent="experiment.spark" abstract="true">
        <constructor-arg name="command">
            <value>--class com.github.projectflink.spark.TPCHQuery3 ${app.path.jobs}/spark-jobs-0.1-SNAPSHOT-SparkBench.jar ${system.spark.config.defaults.spark.master} ${system.hadoop-1.path.input}/tpch3.30G/lineitem.tbl ${system.hadoop-1.path.input}/tpch3.30G/customer.tbl ${system.hadoop-1.path.input}/tpch3.30G/orders.tbl  ${system.hadoop-1.path.output}/tpch3</value>
        </constructor-arg>
        <constructor-arg name="inputs">
            <set value-type="eu.stratosphere.peel.core.beans.data.DataSet">
                <ref bean="dataset.tpch3.30G.lineitem"/>
                <ref bean="dataset.tpch3.30G.orders" />
                <ref bean="dataset.tpch3.30G.customer" />
            </set>
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.tpch3"/>
        </constructor-arg>
    </bean>

    <bean id="experiment.spark.tpch3.40G" parent="experiment.spark" abstract="true">
        <constructor-arg name="command">
            <value>--class com.github.projectflink.spark.TPCHQuery3 ${app.path.jobs}/spark-jobs-0.1-SNAPSHOT-SparkBench.jar ${system.spark.config.defaults.spark.master} ${system.hadoop-1.path.input}/tpch3.40G/lineitem.tbl ${system.hadoop-1.path.input}/tpch3.40G/customer.tbl ${system.hadoop-1.path.input}/tpch3.40G/orders.tbl  ${system.hadoop-1.path.output}/tpch3</value>
        </constructor-arg>
        <constructor-arg name="inputs">
            <set value-type="eu.stratosphere.peel.core.beans.data.DataSet">
                <ref bean="dataset.tpch3.40G.lineitem"/>
                <ref bean="dataset.tpch3.40G.orders" />
                <ref bean="dataset.tpch3.40G.customer" />
            </set>
        </constructor-arg>
        <constructor-arg name="output">
            <ref bean="experiment.output.hdfs.tpch3"/>
        </constructor-arg>
    </bean>


    <!--************************************************************************
    * Fixtures
    *************************************************************************-->

    <bean id="tpch3.flink.10G.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.tpch3.10G">
                    <constructor-arg name="name" value="tpch3.10G.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.flink.10G.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.tpch3.10G">
                    <constructor-arg name="name" value="tpch3.10G.dop64.men36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.flink.20G.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.tpch3.20G">
                    <constructor-arg name="name" value="tpch3.20G.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.flink.20G.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.tpch3.20G">
                    <constructor-arg name="name" value="tpch3.20G.dop64.men36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.flink.30G.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.tpch3.30G">
                    <constructor-arg name="name" value="tpch3.30G.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.flink.30G.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.tpch3.30G">
                    <constructor-arg name="name" value="tpch3.30G.dop64.men36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.flink.40G.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

     <bean id="tpch3.flink.40G.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.flink.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop64.mem5G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 5120
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop64.mem10G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 10240
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop64.mem20G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 64
                            system.flink.config.yaml.taskmanager.heap.mb = 20480
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop48.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-8", "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 48
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop32.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-9", "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 32
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.flink.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop16.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-10" ]
                            system.flink.config.yaml.parallelization.degree.default = 16
                            system.flink.config.yaml.taskmanager.heap.mb = 36863
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.spark.10G.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.tpch3.10G">
                    <constructor-arg name="name" value="tpch3.10G.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.spark.10G.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.tpch3.10G">
                    <constructor-arg name="name" value="tpch3.10G.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.spark.20G.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.tpch3.20G">
                    <constructor-arg name="name" value="tpch3.20G.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.spark.20G.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.tpch3.20G">
                    <constructor-arg name="name" value="tpch3.20G.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.spark.30G.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.tpch3.30G">
                    <constructor-arg name="name" value="tpch3.30G.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.spark.30G.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.tpch3.30G">
                    <constructor-arg name="name" value="tpch3.30G.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.spark.40G.default" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.single-run"/>
                    <constructor-arg name="runs" value="1"/>
                    <constructor-arg name="config">
                        <value/>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>

    <bean id="tpch3.spark.40G.cloud-7" class="eu.stratosphere.peel.core.beans.experiment.ExperimentSuite">
        <constructor-arg name="experiments">
            <list>
                <bean parent="experiment.spark.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop64.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop64.mem5G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "5120m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "5120m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "5120m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop64.mem10G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "10240m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "10240m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "10240m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop64.mem20G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-7", "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 64
                            system.spark.config.defaults.spark.executor.memory = "20480m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "20480m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "20480m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop48.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-8", "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 48
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop32.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-9", "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 32
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
                <bean parent="experiment.spark.tpch3.40G">
                    <constructor-arg name="name" value="tpch3.40G.dop16.mem36G"/>
                    <constructor-arg name="config">
                        <value>
                            experiment.timeout = 12000
                            system.default.config.slaves = [ "cloud-10" ]
                            system.spark.config.defaults.spark.default.parallelism = 16
                            system.spark.config.defaults.spark.executor.memory = "36864m"
                            system.spark.config.env.SPARK_EXECUTOR_MEMORY = "36864m"
                            system.spark.config.env.SPARK_WORKER_MEMORY = "36864m"
                        </value>
                    </constructor-arg>
                </bean>
            </list>
        </constructor-arg>
    </bean>
 
</beans>